[1mdiff --git a/axes/utils/tradera_parser.py b/axes/utils/tradera_parser.py[m
[1mnew file mode 100644[m
[1mindex 0000000..3924b4b[m
[1m--- /dev/null[m
[1m+++ b/axes/utils/tradera_parser.py[m
[36m@@ -0,0 +1,615 @@[m
[32m+[m[32mimport re[m
[32m+[m[32mimport requests[m
[32m+[m[32mfrom bs4 import BeautifulSoup[m
[32m+[m[32mfrom urllib.parse import urlparse, parse_qs[m
[32m+[m[32mfrom typing import Dict, Optional, List[m
[32m+[m[32mimport logging[m
[32m+[m[32mfrom datetime import datetime, timedelta[m
[32m+[m
[32m+[m[32mlogger = logging.getLogger(__name__)[m
[32m+[m
[32m+[m
[32m+[m[32mclass TraderaParser:[m
[32m+[m[32m    """Parser f√∂r Tradera-auktioner"""[m
[32m+[m
[32m+[m[32m    def __init__(self):[m
[32m+[m[32m        self.session = requests.Session()[m
[32m+[m[32m        self.session.headers.update([m
[32m+[m[32m            {[m
[32m+[m[32m                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"[m
[32m+[m[32m            }[m
[32m+[m[32m        )[m
[32m+[m
[32m+[m[32m    def is_tradera_url(self, url: str) -> bool:[m
[32m+[m[32m        """Kontrollera om URL √§r en giltig Tradera-auktions-URL"""[m
[32m+[m[32m        try:[m
[32m+[m[32m            parsed = urlparse(url)[m
[32m+[m[32m            return ([m
[32m+[m[32m                parsed.netloc == "www.tradera.com"[m
[32m+[m[32m                and parsed.path.startswith("/item/")[m
[32m+[m[32m                and len(parsed.path.split("/")) >= 4[m
[32m+[m[32m            )[m
[32m+[m[32m        except Exception:[m
[32m+[m[32m            return False[m
[32m+[m
[32m+[m[32m    def extract_item_id(self, url: str) -> Optional[str]:[m
[32m+[m[32m        """Extrahera objekt-ID fr√•n Tradera URL"""[m
[32m+[m[32m        try:[m
[32m+[m[32m            # URL-format: /item/343327/683953821/yxa-saw-stamplat-ph-[m
[32m+[m[32m            path_parts = urlparse(url).path.split("/")[m
[32m+[m[32m            if len(path_parts) >= 4:[m
[32m+[m[32m                return path_parts[3]  # 683953821[m
[32m+[m[32m            return None[m
[32m+[m[32m        except Exception:[m
[32m+[m[32m            return None[m
[32m+[m
[32m+[m[32m    def parse_tradera_page(self, url: str) -> Dict:[m
[32m+[m[32m        """Huvudfunktion f√∂r att parsa Tradera-auktionssida"""[m
[32m+[m[32m        if not self.is_tradera_url(url):[m
[32m+[m[32m            raise ValueError("Ogiltig Tradera URL")[m
[32m+[m
[32m+[m[32m        try:[m
[32m+[m[32m            response = self.session.get(url, timeout=10)[m
[32m+[m[32m            response.raise_for_status()[m
[32m+[m
[32m+[m[32m            soup = BeautifulSoup(response.content, "html.parser")[m
[32m+[m[32m            prices = self._extract_prices(soup)[m
[32m+[m
[32m+[m[32m            return {[m
[32m+[m[32m                "title": self._extract_title(soup),[m
[32m+[m[32m                "description": self._extract_description(soup),[m
[32m+[m[32m                "seller_alias": self._extract_seller_alias(soup),[m
[32m+[m[32m                "prices": prices,[m
[32m+[m[32m                "item_id": self.extract_item_id(url),[m
[32m+[m[32m                "images": self._extract_images(soup),[m
[32m+[m[32m                "auction_end_date": self._extract_auction_end_date(soup),[m
[32m+[m[32m                "url": url,[m
[32m+[m[32m            }[m
[32m+[m
[32m+[m[32m        except requests.RequestException as e:[m
[32m+[m[32m            logger.error(f"Fel vid h√§mtning av Tradera-sida: {e}")[m
[32m+[m[32m            raise ValueError(f"Kunde inte h√§mta auktionssida: {e}")[m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            logger.error(f"Fel vid parsning av Tradera-sida: {e}")[m
[32m+[m[32m            raise ValueError(f"Kunde inte parsa auktionssida: {e}")[m
[32m+[m
[32m+[m[32m    def _extract_auction_end_date(self, soup: BeautifulSoup) -> Optional[str]:[m
[32m+[m[32m        """Extrahera auktionsslutdatum"""[m
[32m+[m[32m        # Leta efter text som indikerar n√§r auktionen slutade[m
[32m+[m[32m        page_text = soup.get_text()[m
[32m+[m
[32m+[m[32m        # M√∂nster f√∂r att hitta slutdatum[m
[32m+[m[32m        date_patterns = [[m
[32m+[m[32m            # Format: "avslutad 27 jul 14:00" (implicit √•r 2025)[m
[32m+[m[32m            r"avslutad\s+(\d{1,2})\s+(jan|feb|mar|apr|maj|jun|jul|aug|sep|okt|nov|dec)\s+(\d{1,2}):(\d{2})",[m
[32m+[m[32m            r"avslutad\s+(\d{1,2})\s+(januari|februari|mars|april|maj|juni|juli|augusti|september|oktober|november|december)\s+(\d{1,2}):(\d{2})",[m
[32m+[m[32m            # Format: "slutade 27 juli 2025"[m
[32m+[m[32m            r"slutade\s+(\d{1,2})\s+(januari|februari|mars|april|maj|juni|juli|augusti|september|oktober|november|december)\s+(\d{4})",[m
[32m+[m[32m            r"slutade\s+(\d{1,2})/(\d{1,2})/(\d{4})",[m
[32m+[m[32m            r"slutade\s+(\d{4})-(\d{1,2})-(\d{1,2})",[m
[32m+[m[32m            r"(\d{1,2})\s+(januari|februari|mars|april|maj|juni|juli|augusti|september|oktober|november|december)\s+(\d{4})\s+slutade",[m
[32m+[m[32m            r"(\d{1,2})/(\d{1,2})/(\d{4})\s+slutade",[m
[32m+[m[32m            r"(\d{4})-(\d{1,2})-(\d{1,2})\s+slutade",[m
[32m+[m[32m        ][m
[32m+[m
[32m+[m[32m        month_names = {[m
[32m+[m[32m            "jan": 1, "januari": 1,[m
[32m+[m[32m            "feb": 2, "februari": 2,[m
[32m+[m[32m            "mar": 3, "mars": 3,[m
[32m+[m[32m            "apr": 4, "april": 4,[m
[32m+[m[32m            "maj": 5,[m
[32m+[m[32m            "jun": 6, "juni": 6,[m
[32m+[m[32m            "jul": 7, "juli": 7,[m
[32m+[m[32m            "aug": 8, "augusti": 8,[m
[32m+[m[32m            "sep": 9, "september": 9,[m
[32m+[m[32m            "okt": 10, "oktober": 10,[m
[32m+[m[32m            "nov": 11, "november": 11,[m
[32m+[m[32m            "dec": 12, "december": 12,[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        for pattern in date_patterns:[m
[32m+[m[32m            match = re.search(pattern, page_text, re.IGNORECASE)[m
[32m+[m[32m            if match:[m
[32m+[m[32m                try:[m
[32m+[m[32m                    groups = match.groups()[m
[32m+[m[32m                    if len(groups) == 4:[m
[32m+[m[32m                        # Format: "avslutad 27 jul 14:00" (4 grupper: dag, m√•nad, timme, minut)[m
[32m+[m[32m                        day = int(groups[0])[m
[32m+[m[32m                        month_name = groups[1].lower()[m
[32m+[m[32m                        # Timme och minut ignoreras f√∂r datum[m
[32m+[m[32m                        if month_name in month_names:[m
[32m+[m[32m                            month = month_names[month_name][m
[32m+[m[41m                            [m
[32m+[m[32m                            # Intelligent √•rbest√§mning baserat p√• dagens datum[m
[32m+[m[32m                            today = datetime.now().date()[m
[32m+[m[32m                            current_year = today.year[m
[32m+[m[32m                            current_month = today.month[m
[32m+[m[41m                            [m
[32m+[m[32m                            # Om auktionsm√•nad √§r senare √§n nuvarande m√•nad,[m[41m [m
[32m+[m[32m                            # och vi √§r i slutet av √•ret, s√• √§r auktionen fr√•n f√∂reg√•ende √•r[m
[32m+[m[32m                            if month > current_month and current_month >= 11:[m
[32m+[m[32m                                year = current_year - 1[m
[32m+[m[32m                            # Om auktionsm√•nad √§r tidigare √§n nuvarande m√•nad,[m
[32m+[m[32m                            # och vi √§r i b√∂rjan av √•ret, s√• √§r auktionen fr√•n f√∂reg√•ende √•r[m
[32m+[m[32m                            elif month < current_month and current_month <= 2:[m
[32m+[m[32m                          